{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2018 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTueGwFWcDK2"
   },
   "source": [
    "# Experiment 1: fixed detector in many scenarios\n",
    "\n",
    "This notebook contains the code for computing the performance of the fixed strategies in various scenarios. The full experiment is described in Sec. 5.2 of CVPR submission \"Learning Intelligent Dialogs for Bounding Box Annotation\". Please note that this notebook does not reproduce the experiment since the starting detector is too strong, there is no re-training, and there are only two iterations being done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1VacJd0VNcb3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import math\n",
    "import gym\n",
    "\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "\n",
    "from sklearn import neural_network, model_selection\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from third_party import np_box_ops\n",
    "import annotator, detector, dialog, environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwMFtKv4MmMB"
   },
   "source": [
    "To specify the experiments, define: \n",
    "\n",
    "*   type of drawing\n",
    "*   desired quality of bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VxqklQG_PQml"
   },
   "outputs": [],
   "source": [
    "# desired quality: high (min_iou=0.7) and low (min_iou=0.5)\n",
    "min_iou = 0.7 # @param [\"0.5\", \"0.7\"]\n",
    "# drawing speed: high (time_draw=7) and low (time_draw=25)\n",
    "time_draw = 7 # @param [\"7\", \"25\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edB2VJm7nsI_"
   },
   "source": [
    "Other parameters of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iuyNuLctrDi7"
   },
   "outputs": [],
   "source": [
    "random_seed = 80590 # global variable that fixes the random seed everywhere for replroducibility of results\n",
    "\n",
    "# what kind of features will be used to represent the state\n",
    "# numerical values 1-20 correspond to one hot encoding of class\n",
    "predictive_fields = ['prediction_score', 'relative_size', 'avg_score', 'dif_avg_score', 'dif_max_score', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "\n",
    "time_verify = 1.8 # @param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oiv682TsBLDf"
   },
   "source": [
    "# Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WXBNH4EY3zYF"
   },
   "outputs": [],
   "source": [
    "# Download GT:\n",
    "# wget wget https://storage.googleapis.com/iad_pascal_annotations_and_detections/pascal_gt_for_iad.h5\n",
    "# Download detections with features\n",
    "# wget https://storage.googleapis.com/iad_pascal_annotations_and_detections/pascal_proposals_plus_features_for_iad.h5\n",
    "\n",
    "download_dir = ''\n",
    "ground_truth = pd.read_hdf(download_dir + 'pascal_gt_for_iad.h5', 'ground_truth')\n",
    "box_proposal_features = pd.read_hdf(download_dir + 'pascal_proposals_plus_features_for_iad.h5', 'box_proposal_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwlNbTtUBqht"
   },
   "source": [
    "# Initialise the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "28W__WtSBvMt"
   },
   "outputs": [],
   "source": [
    "annotator_real = annotator.AnnotatorSimple(ground_truth, random_seed, time_verify, time_draw, min_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ptK6iHEGc8UJ"
   },
   "outputs": [],
   "source": [
    "# better call it image_class_pairs later\n",
    "image_class = ground_truth[['image_id', 'class_id']]\n",
    "image_class = image_class.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cylItnHrT-4n"
   },
   "source": [
    "Select the trainig and testing data according to the selected fold. We split all images in 10 approximately equal parts and each fold includes these images together with all classes present in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7jN8cxbd_o_k"
   },
   "outputs": [],
   "source": [
    "unique_image = image_class['image_id'].drop_duplicates()\n",
    "\n",
    "# divide the images into exponentially growing groups\n",
    "im1 = unique_image.iloc[157]\n",
    "im2 = unique_image.iloc[157+157]\n",
    "im3 = unique_image.iloc[157+157+314]\n",
    "im4 = unique_image.iloc[157+157+314+625]\n",
    "im5 = unique_image.iloc[157+157+314+625+1253]\n",
    "\n",
    "# image_class pairs groups are determined by the images in them\n",
    "image_class_array = image_class.values[:,0]\n",
    "in1 = np.searchsorted(image_class_array, im1, side='right')\n",
    "in2 = np.searchsorted(image_class_array, im2, side='right')\n",
    "in3 = np.searchsorted(image_class_array, im3, side='right')\n",
    "in4 = np.searchsorted(image_class_array, im4, side='right')\n",
    "in5 = np.searchsorted(image_class_array, im5, side='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1PJckyYGfP3"
   },
   "source": [
    "# Batch 1: Annotate 3.125% of data with strategy X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IABYNoFcEfRw"
   },
   "outputs": [],
   "source": [
    "the_detector = detector.Detector(box_proposal_features, predictive_fields)\n",
    "image_class_current = image_class.iloc[0:in1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "height": 300,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 7
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1349,
     "status": "ok",
     "timestamp": 1516022147699,
     "user": {},
     "user_tz": -60
    },
    "id": "LmwTDdPtGfP6",
    "outputId": "e16dac03-0cdb-4c9e-b0fe-6065db7bb690"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window[\"32907156-f9f6-11e7-8447-5065f3390f23\"] = colab.output.setOutputHeight(300, false, {\"interactive\": true});\n",
       "//# sourceURL=js_cdfe1c1d05"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript at 0xf4e4810>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  241 episodes with strategy X\n",
      "Episode  0: D\n",
      "Episode  1: D\n",
      "Episode  2: D\n",
      "Episode  3: D\n",
      "Episode  4: D\n",
      "Episode  5: D\n",
      "Episode  6: D\n",
      "Episode  7: D\n",
      "Episode  8: D\n",
      "Episode  9: D\n",
      "Episode  10: D\n",
      "Episode  11: D\n",
      "Episode  12: D\n",
      "Episode  13: D\n",
      "Episode  14: D\n",
      "Episode  15: D\n",
      "Episode  16: D\n",
      "Episode  17: D\n",
      "Episode  18: D\n",
      "Episode  19: D\n",
      "Episode  20: D\n",
      "Episode  21: D\n",
      "Episode  22: D\n",
      "Episode  23: D\n",
      "Episode  24: D\n",
      "Episode  25: D\n",
      "Episode  26: D\n",
      "Episode  27: D\n",
      "Episode  28: D\n",
      "Episode  29: D\n",
      "Episode  30: D\n",
      "Episode  31: D\n",
      "Episode  32: D\n",
      "Episode  33: D\n",
      "Episode  34: D\n",
      "Episode  35: D\n",
      "Episode  36: D\n",
      "Episode  37: D\n",
      "Episode  38: D\n",
      "Episode  39: D\n",
      "Episode  40: D\n",
      "Episode  41: D\n",
      "Episode  42: D\n",
      "Episode  43: D\n",
      "Episode  44: D\n",
      "Episode  45: D\n",
      "Episode  46: D\n",
      "Episode  47: D\n",
      "Episode  48: D\n",
      "Episode  49: D\n",
      "Episode  50: D\n",
      "Episode  51: D\n",
      "Episode  52: D\n",
      "Episode  53: D\n",
      "Episode  54: D\n",
      "Episode  55: D\n",
      "Episode  56: D\n",
      "Episode  57: D\n",
      "Episode  58: D\n",
      "Episode  59: D\n",
      "Episode  60: D\n",
      "Episode  61: D\n",
      "Episode  62: D\n",
      "Episode  63: D\n",
      "Episode  64: D\n",
      "Episode  65: D\n",
      "Episode  66: D\n",
      "Episode  67: D\n",
      "Episode  68: D\n",
      "Episode  69: D\n",
      "Episode  70: D\n",
      "Episode  71: D\n",
      "Episode  72: D\n",
      "Episode  73: D\n",
      "Episode  74: D\n",
      "Episode  75: D\n",
      "Episode  76: D\n",
      "Episode  77: D\n",
      "Episode  78: D\n",
      "Episode  79: D\n",
      "Episode  80: D\n",
      "Episode  81: D\n",
      "Episode  82: D\n",
      "Episode  83: D\n",
      "Episode  84: D\n",
      "Episode  85: D\n",
      "Episode  86: D\n",
      "Episode  87: D\n",
      "Episode  88: D\n",
      "Episode  89: D\n",
      "Episode  90: D\n",
      "Episode  91: D\n",
      "Episode  92: D\n",
      "Episode  93: D\n",
      "Episode  94: D\n",
      "Episode  95: D\n",
      "Episode  96: D\n",
      "Episode  97: D\n",
      "Episode  98: D\n",
      "Episode  99: D\n",
      "Episode  100: D\n",
      "Episode  101: D\n",
      "Episode  102: D\n",
      "Episode  103: D\n",
      "Episode  104: D\n",
      "Episode  105: D\n",
      "Episode  106: D\n",
      "Episode  107: D\n",
      "Episode  108: D\n",
      "Episode  109: D\n",
      "Episode  110: D\n",
      "Episode  111: D\n",
      "Episode  112: D\n",
      "Episode  113: D\n",
      "Episode  114: D\n",
      "Episode  115: D\n",
      "Episode  116: D\n",
      "Episode  117: D\n",
      "Episode  118: D\n",
      "Episode  119: D\n",
      "Episode  120: D\n",
      "Episode  121: D\n",
      "Episode  122: D\n",
      "Episode  123: D\n",
      "Episode  124: D\n",
      "Episode  125: D\n",
      "Episode  126: D\n",
      "Episode  127: D\n",
      "Episode  128: D\n",
      "Episode  129: D\n",
      "Episode  130: D\n",
      "Episode  131: D\n",
      "Episode  132: D\n",
      "Episode  133: D\n",
      "Episode  134: D\n",
      "Episode  135: D\n",
      "Episode  136: D\n",
      "Episode  137: D\n",
      "Episode  138: D\n",
      "Episode  139: D\n",
      "Episode  140: D\n",
      "Episode  141: D\n",
      "Episode  142: D\n",
      "Episode  143: D\n",
      "Episode  144: D\n",
      "Episode  145: D\n",
      "Episode  146: D\n",
      "Episode  147: D\n",
      "Episode  148: D\n",
      "Episode  149: D\n",
      "Episode  150: D\n",
      "Episode  151: D\n",
      "Episode  152: D\n",
      "Episode  153: D\n",
      "Episode  154: D\n",
      "Episode  155: D\n",
      "Episode  156: D\n",
      "Episode  157: D\n",
      "Episode  158: D\n",
      "Episode  159: D\n",
      "Episode  160: D\n",
      "Episode  161: D\n",
      "Episode  162: D\n",
      "Episode  163: D\n",
      "Episode  164: D\n",
      "Episode  165: D\n",
      "Episode  166: D\n",
      "Episode  167: D\n",
      "Episode  168: D\n",
      "Episode  169: D\n",
      "Episode  170: D\n",
      "Episode  171: D\n",
      "Episode  172: D\n",
      "Episode  173: D\n",
      "Episode  174: D\n",
      "Episode  175: D\n",
      "Episode  176: D\n",
      "Episode  177: D\n",
      "Episode  178: D\n",
      "Episode  179: D\n",
      "Episode  180: D\n",
      "Episode  181: D\n",
      "Episode  182: D\n",
      "Episode  183: D\n",
      "Episode  184: D\n",
      "Episode  185: D\n",
      "Episode  186: D\n",
      "Episode  187: D\n",
      "Episode  188: D\n",
      "Episode  189: D\n",
      "Episode  190: D\n",
      "Episode  191: D\n",
      "Episode  192: D\n",
      "Episode  193: D\n",
      "Episode  194: D\n",
      "Episode  195: D\n",
      "Episode  196: D\n",
      "Episode  197: D\n",
      "Episode  198: D\n",
      "Episode  199: D\n",
      "Episode  200: D\n",
      "Episode  201: D\n",
      "Episode  202: D\n",
      "Episode  203: D\n",
      "Episode  204: D\n",
      "Episode  205: D\n",
      "Episode  206: D\n",
      "Episode  207: D\n",
      "Episode  208: D\n",
      "Episode  209: D\n",
      "Episode  210: D\n",
      "Episode  211: D\n",
      "Episode  212: D\n",
      "Episode  213: D\n",
      "Episode  214: D\n",
      "Episode  215: D\n",
      "Episode  216: D\n",
      "Episode  217: D\n",
      "Episode  218: D\n",
      "Episode  219: D\n",
      "Episode  220: D\n",
      "Episode  221: D\n",
      "Episode  222: D\n",
      "Episode  223: D\n",
      "Episode  224: D\n",
      "Episode  225: D\n",
      "Episode  226: D\n",
      "Episode  227: D\n",
      "Episode  228: D\n",
      "Episode  229: D\n",
      "Episode  230: D\n",
      "Episode  231: D\n",
      "Episode  232: D\n",
      "Episode  233: D\n",
      "Episode  234: D\n",
      "Episode  235: D\n",
      "Episode  236: D\n",
      "Episode  237: D\n",
      "Episode  238: D\n",
      "Episode  239: D\n",
      "Episode  240: D\n",
      "total_reward =  -1687\n",
      "average episode reward =  -7.0\n"
     ]
    }
   ],
   "source": [
    "%output_height 300\n",
    "\n",
    "env = environment.AnnotatingDataset(annotator_real, the_detector, image_class_current)\n",
    "print('Running ', len(env.image_class), 'episodes with strategy X')\n",
    "\n",
    "total_reward = 0\n",
    "new_ground_truth_all = []\n",
    "all_annotations = dict()\n",
    "\n",
    "for i in range(len(env.image_class)):\n",
    "  print('Episode ', i, end = ': ')\n",
    "  state = env.reset(current_index=i)\n",
    "  agent = dialog.FixedDialog(0)\n",
    "  done = False\n",
    "  while not(done):\n",
    "    action = agent.get_next_action(state)    \n",
    "    if action==0:\n",
    "      print('V', end='')\n",
    "    elif action==1:\n",
    "      print('D', end='')\n",
    "    next_state, reward, done, coordinates = env.step(action)\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "\n",
    "  dataset_id = env.current_image\n",
    "\n",
    "  # ground truth with which we will initialise the new user\n",
    "  new_ground_truth = {}\n",
    "  new_ground_truth['image_id'] = dataset_id\n",
    "  new_ground_truth['class_id'] = env.current_class\n",
    "  new_ground_truth['xmax'] = coordinates['xmax']\n",
    "  new_ground_truth['xmin'] = coordinates['xmin']\n",
    "  new_ground_truth['ymax'] = coordinates['ymax']\n",
    "  new_ground_truth['ymin'] = coordinates['ymin']\n",
    "  new_ground_truth_all.append(new_ground_truth)\n",
    "\n",
    "\n",
    "  if dataset_id not in all_annotations:\n",
    "    current_annotation = dict()\n",
    "    current_annotation['boxes'] = np.array([[coordinates['ymin'], coordinates['xmin'], coordinates['ymax'], coordinates['xmax']]], dtype=np.int32)\n",
    "    current_annotation['box_labels'] = np.array([env.current_class])\n",
    "    all_annotations[dataset_id] = current_annotation\n",
    "\n",
    "  else:\n",
    "    all_annotations[dataset_id]['boxes'] = np.append(all_annotations[dataset_id]['boxes'],  np.array([[coordinates['ymin'], coordinates['xmin'], coordinates['ymax'], coordinates['xmax']]], dtype=np.int32), axis=0)\n",
    "    all_annotations[dataset_id]['box_labels'] = np.append(all_annotations[dataset_id]['box_labels'], np.array([env.current_class]))     \n",
    "\n",
    "  print()\n",
    "\n",
    "print('total_reward = ', total_reward)    \n",
    "print('average episode reward = ', total_reward/len(env.image_class))\n",
    "\n",
    "new_ground_truth_all = pd.DataFrame(new_ground_truth_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LxSGM47Gs0g"
   },
   "source": [
    "# Batch 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yk_PHZ6Q8pYh"
   },
   "source": [
    "Starting from Batch 3 the code will be just repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qa2-D5wq-NUN"
   },
   "outputs": [],
   "source": [
    "ground_truth_new = pd.DataFrame(new_ground_truth_all)\n",
    "annotator_new = annotator.AnnotatorSimple(ground_truth_new, random_seed, time_verify, time_draw, min_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "height": 300,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 16
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3472,
     "status": "ok",
     "timestamp": 1516022151275,
     "user": {},
     "user_tz": -60
    },
    "id": "NwJ5ASzMFL46",
    "outputId": "61d1c4b2-92c0-4446-f1be-7ca2b3c4ce7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  241 episodes with strategy V3X\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window[\"336cdd26-f9f6-11e7-8447-5065f3390f23\"] = colab.output.setOutputHeight(300, false, {\"interactive\": true});\n",
       "//# sourceURL=js_c14892a5ae"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript at 0xee31a10>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: VVVD\n",
      "1: V\n",
      "2: V\n",
      "3: V\n",
      "4: V\n",
      "5: V\n",
      "6: V\n",
      "7: V\n",
      "8: V\n",
      "9: V\n",
      "10: VVV\n",
      "11: VVV\n",
      "12: VVVD\n",
      "13: VVVD\n",
      "14: V\n",
      "15: V\n",
      "16: V\n",
      "17: VV\n",
      "18: VVVD\n",
      "19: VV\n",
      "20: V\n",
      "21: VVVD\n",
      "22: VVVD\n",
      "23: V\n",
      "24: V\n",
      "25: V\n",
      "26: V\n",
      "27: V\n",
      "28: VV\n",
      "29: V\n",
      "30: V\n",
      "31: V\n",
      "32: V\n",
      "33: VVVD\n",
      "34: V\n",
      "35: VV\n",
      "36: VVVD\n",
      "37: VVVD\n",
      "38: V\n",
      "39: VV\n",
      "40: VVVD\n",
      "41: VVVD\n",
      "42: VVVD\n",
      "43: VV\n",
      "44: V\n",
      "45: V\n",
      "46: V\n",
      "47: V\n",
      "48: VVV\n",
      "49: V\n",
      "50: VVVD\n",
      "51: V\n",
      "52: V\n",
      "53: VVVD\n",
      "54: VVV\n",
      "55: VVVD\n",
      "56: VVV\n",
      "57: V\n",
      "58: V\n",
      "59: VVVD\n",
      "60: V\n",
      "61: VVVD\n",
      "62: V\n",
      "63: V\n",
      "64: V\n",
      "65: VVVD\n",
      "66: VVVD\n",
      "67: V\n",
      "68: VV\n",
      "69: VV\n",
      "70: V\n",
      "71: V\n",
      "72: V\n",
      "73: V\n",
      "74: VVVD\n",
      "75: VVVD\n",
      "76: V\n",
      "77: V\n",
      "78: V\n",
      "79: V\n",
      "80: V\n",
      "81: VV\n",
      "82: V\n",
      "83: V\n",
      "84: VVVD\n",
      "85: VV\n",
      "86: VVVD\n",
      "87: VVVD\n",
      "88: V\n",
      "89: V\n",
      "90: VVVD\n",
      "91: V\n",
      "92: VVVD\n",
      "93: VVVD\n",
      "94: V\n",
      "95: VVVD\n",
      "96: V\n",
      "97: V\n",
      "98: V\n",
      "99: V\n",
      "100: V\n",
      "101: V\n",
      "102: VVVD\n",
      "103: VVVD\n",
      "104: VVVD\n",
      "105: V\n",
      "106: VVVD\n",
      "107: V\n",
      "108: V\n",
      "109: V\n",
      "110: V\n",
      "111: VVVD\n",
      "112: V\n",
      "113: V\n",
      "114: V\n",
      "115: V\n",
      "116: V\n",
      "117: V\n",
      "118: V\n",
      "119: V\n",
      "120: VVVD\n",
      "121: V\n",
      "122: VVVD\n",
      "123: V\n",
      "124: V\n",
      "125: V\n",
      "126: V\n",
      "127: VVVD\n",
      "128: V\n",
      "129: V\n",
      "130: V\n",
      "131: V\n",
      "132: VVVD\n",
      "133: V\n",
      "134: V\n",
      "135: VVV\n",
      "136: VVVD\n",
      "137: VVVD\n",
      "138: V\n",
      "139: VVVD\n",
      "140: V\n",
      "141: V\n",
      "142: VVV\n",
      "143: V\n",
      "144: VVVD\n",
      "145: VVV\n",
      "146: V\n",
      "147: V\n",
      "148: V\n",
      "149: V\n",
      "150: V\n",
      "151: V\n",
      "152: V\n",
      "153: VVVD\n",
      "154: V\n",
      "155: V\n",
      "156: V\n",
      "157: VVVD\n",
      "158: V\n",
      "159: V\n",
      "160: V\n",
      "161: VV\n",
      "162: VV\n",
      "163: V\n",
      "164: VVVD\n",
      "165: VVVD\n",
      "166: VVVD\n",
      "167: VVVD\n",
      "168: V\n",
      "169: V\n",
      "170: V\n",
      "171: V\n",
      "172: V\n",
      "173: VVVD\n",
      "174: V\n",
      "175: V\n",
      "176: VVVD\n",
      "177: V\n",
      "178: VVVD\n",
      "179: VVVD\n",
      "180: V\n",
      "181: VVVD\n",
      "182: VVVD\n",
      "183: VVVD\n",
      "184: VVVD\n",
      "185: V\n",
      "186: VV\n",
      "187: V\n",
      "188: V\n",
      "189: V\n",
      "190: V\n",
      "191: V\n",
      "192: VVVD\n",
      "193: V\n",
      "194: V\n",
      "195: V\n",
      "196: VV\n",
      "197: VVVD\n",
      "198: V\n",
      "199: VV\n",
      "200: VVVD\n",
      "201: V\n",
      "202: V\n",
      "203: V\n",
      "204: V\n",
      "205: V\n",
      "206: VVVD\n",
      "207: VVVD\n",
      "208: VVVD\n",
      "209: VVVD\n",
      "210: V\n",
      "211: V\n",
      "212: VVV\n",
      "213: V\n",
      "214: V\n",
      "215: VV\n",
      "216: VVVD\n",
      "217: VVVD\n",
      "218: V\n",
      "219: V\n",
      "220: V\n",
      "221: VVVD\n",
      "222: V\n",
      "223: VVVD\n",
      "224: V\n",
      "225: V\n",
      "226: V\n",
      "227: VVVD\n",
      "228: V\n",
      "229: V\n",
      "230: VVVD\n",
      "231: V\n",
      "232: V\n",
      "233: V\n",
      "234: VVVD\n",
      "235: VVVD\n",
      "236: VVVD\n",
      "237: V\n",
      "238: V\n",
      "239: V\n",
      "240: VV\n",
      "Average episode reward =  -5.18423236515\n"
     ]
    }
   ],
   "source": [
    "# @title Collect data for classifier\n",
    "env = environment.AnnotatingDataset(annotator_new, the_detector, image_class_current)\n",
    "\n",
    "print('Running ', len(env.image_class), 'episodes with strategy V3X')\n",
    "\n",
    "%output_height 300\n",
    "total_reward = 0\n",
    "\n",
    "data_for_classifier = []\n",
    "\n",
    "for i in range(len(env.image_class)):\n",
    "  print(i, end = ': ')\n",
    "  agent = dialog.FixedDialog(3)\n",
    "  state = env.reset(current_index=i)\n",
    "\n",
    "  done = False\n",
    "  while not(done):\n",
    "    action = agent.get_next_action(state)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    if action==0:\n",
    "      state_dict = dict(state)\n",
    "      state_dict['is_accepted'] = done\n",
    "      data_for_classifier.append(state_dict)\n",
    "      print('V', end='')\n",
    "    elif action==1:\n",
    "      print('D', end='')\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "\n",
    "  print()\n",
    "\n",
    "print('Average episode reward = ', total_reward/len(env.image_class))\n",
    "\n",
    "data_for_classifier = pd.DataFrame(data_for_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "height": 105,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22900,
     "status": "ok",
     "timestamp": 1516022174199,
     "user": {},
     "user_tz": -60
    },
    "id": "64kJJVp5AtHp",
    "outputId": "906636c8-f041-4406-c50d-973d5163df1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating parameters' values... This might take some time.\n",
      "best score =  -0.613398861011\n",
      "best parameters =  {'hidden_layer_sizes': (20, 20, 20, 20, 20), 'activation': 'relu', 'alpha': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    }
   ],
   "source": [
    "# @title Train classification model (might take some time)\n",
    "\n",
    "#model_mlp = neural_network.MLPClassifier(alpha = 0.0001, activation = 'relu', hidden_layer_sizes = (50, 50, 50, 50, 50), random_state=602)\n",
    "#model_for_agent = model_mlp.fit(data_from_Vx3X[predictive_fields], data_from_Vx3X['is_accepted'])\n",
    "np.random.seed(random_seed) # for reproducibility of fitting the classifier and cross-validation\n",
    "\n",
    "print('Cross-validating parameters\\' values... This might take some time.')\n",
    "\n",
    "# possible parameter values\n",
    "parameters = {'hidden_layer_sizes': ((20, 20, 20), (50, 50, 50), (80, 80, 80), (20, 20, 20, 20), (50, 50, 50, 50), (80, 80, 80, 80), (20, 20, 20, 20, 20), (50, 50, 50, 50, 50), (80, 80, 80, 80, 80)), 'activation': ('logistic', 'relu'), 'alpha': [0.0001, 0.001, 0.01]}\n",
    "model_mlp = neural_network.MLPClassifier()\n",
    "# cross-validate parameters\n",
    "grid_search = model_selection.GridSearchCV(model_mlp, parameters, scoring='neg_log_loss', refit=True)\n",
    "grid_search.fit(data_for_classifier[predictive_fields], data_for_classifier['is_accepted'])\n",
    "print('best score = ', grid_search.best_score_)\n",
    "print('best parameters = ', grid_search.best_params_)\n",
    "# use the model with the best parameters\n",
    "model_for_agent = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q00bs0Ns5J_o"
   },
   "source": [
    "**Now is the time to retrain the detector and obtain new box_proposal_features. This is not done in this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Nx2VHs2iG_Eg"
   },
   "outputs": [],
   "source": [
    "image_class_current = image_class.iloc[in1:in2]\n",
    "the_detector = detector.Detector(box_proposal_features, predictive_fields)\n",
    "agent = dialog.DialogProb(model_for_agent, annotator_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "height": 300,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 14
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5293,
     "status": "ok",
     "timestamp": 1516022207595,
     "user": {},
     "user_tz": -60
    },
    "id": "kRmEpo9pG_KA",
    "outputId": "c3a50b6f-7656-404b-a924-59888aec03a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  250 episodes with strategy IAD-Prob\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window[\"55478d10-f9f6-11e7-8447-5065f3390f23\"] = colab.output.setOutputHeight(300, false, {\"interactive\": true});\n",
       "//# sourceURL=js_1f9aff6729"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript at 0xb81dfd0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intelligent dialog strategy\n",
      "0: V\n",
      "1: V\n",
      "2: V\n",
      "3: V\n",
      "4: V\n",
      "5: V\n",
      "6: V\n",
      "7: VV\n",
      "8: V\n",
      "9: V\n",
      "10: D\n",
      "11: V\n",
      "12: V\n",
      "13: V\n",
      "14: V\n",
      "15: V\n",
      "16: V\n",
      "17: V\n",
      "18: D\n",
      "19: V\n",
      "20: V\n",
      "21: V\n",
      "22: V\n",
      "23: D\n",
      "24: VD\n",
      "25: VD\n",
      "26: V\n",
      "27: V\n",
      "28: V\n",
      "29: V\n",
      "30: D\n",
      "31: V\n",
      "32: V\n",
      "33: VVD\n",
      "34: VVVVD\n",
      "35: V\n",
      "36: VD\n",
      "37: D\n",
      "38: V\n",
      "39: V\n",
      "40: V\n",
      "41: VVD\n",
      "42: VV\n",
      "43: V\n",
      "44: V\n",
      "45: VD\n",
      "46: D\n",
      "47: V\n",
      "48: VD\n",
      "49: D\n",
      "50: V\n",
      "51: V\n",
      "52: D\n",
      "53: V\n",
      "54: V\n",
      "55: V\n",
      "56: V\n",
      "57: V\n",
      "58: V\n",
      "59: VVD\n",
      "60: VD\n",
      "61: VD\n",
      "62: V\n",
      "63: V\n",
      "64: V\n",
      "65: V\n",
      "66: V\n",
      "67: V\n",
      "68: VVD\n",
      "69: V\n",
      "70: VVVVD\n",
      "71: V\n",
      "72: D\n",
      "73: D\n",
      "74: V\n",
      "75: V\n",
      "76: V\n",
      "77: D\n",
      "78: V\n",
      "79: VD\n",
      "80: VVD\n",
      "81: V\n",
      "82: V\n",
      "83: V\n",
      "84: VVV\n",
      "85: V\n",
      "86: V\n",
      "87: D\n",
      "88: V\n",
      "89: V\n",
      "90: V\n",
      "91: D\n",
      "92: V\n",
      "93: V\n",
      "94: V\n",
      "95: V\n",
      "96: VD\n",
      "97: V\n",
      "98: VD\n",
      "99: V\n",
      "100: V\n",
      "101: V\n",
      "102: V\n",
      "103: D\n",
      "104: D\n",
      "105: V\n",
      "106: V\n",
      "107: V\n",
      "108: VVD\n",
      "109: VD\n",
      "110: V\n",
      "111: D\n",
      "112: V\n",
      "113: V\n",
      "114: V\n",
      "115: VD\n",
      "116: V\n",
      "117: V\n",
      "118: V\n",
      "119: V\n",
      "120: V\n",
      "121: V\n",
      "122: VV\n",
      "123: D\n",
      "124: V\n",
      "125: V\n",
      "126: D\n",
      "127: D\n",
      "128: V\n",
      "129: V\n",
      "130: V\n",
      "131: V\n",
      "132: VD\n",
      "133: V\n",
      "134: V\n",
      "135: V\n",
      "136: V\n",
      "137: V\n",
      "138: D\n",
      "139: V\n",
      "140: VD\n",
      "141: V\n",
      "142: D\n",
      "143: V\n",
      "144: V\n",
      "145: V\n",
      "146: V\n",
      "147: V\n",
      "148: D\n",
      "149: V\n",
      "150: V\n",
      "151: V\n",
      "152: V\n",
      "153: V\n",
      "154: VD\n",
      "155: VVD\n",
      "156: D\n",
      "157: D\n",
      "158: V\n",
      "159: V\n",
      "160: V\n",
      "161: V\n",
      "162: V\n",
      "163: V\n",
      "164: V\n",
      "165: V\n",
      "166: V\n",
      "167: V\n",
      "168: VVV\n",
      "169: VD\n",
      "170: V\n",
      "171: VD\n",
      "172: VD\n",
      "173: V\n",
      "174: V\n",
      "175: D\n",
      "176: V\n",
      "177: V\n",
      "178: V\n",
      "179: V\n",
      "180: V\n",
      "181: D\n",
      "182: V\n",
      "183: V\n",
      "184: V\n",
      "185: V\n",
      "186: D\n",
      "187: V\n",
      "188: D\n",
      "189: VD\n",
      "190: V\n",
      "191: V\n",
      "192: V\n",
      "193: V\n",
      "194: V\n",
      "195: V\n",
      "196: V\n",
      "197: V\n",
      "198: VD\n",
      "199: V\n",
      "200: V\n",
      "201: V\n",
      "202: D\n",
      "203: D\n",
      "204: VV\n",
      "205: D\n",
      "206: D\n",
      "207: VV\n",
      "208: VVVVVVVVVVVVVVVVVVVVVVD\n",
      "209: D\n",
      "210: V\n",
      "211: VD\n",
      "212: D\n",
      "213: V\n",
      "214: D\n",
      "215: V\n",
      "216: V\n",
      "217: VVD\n",
      "218: V\n",
      "219: VV\n",
      "220: V\n",
      "221: V\n",
      "222: V\n",
      "223: D\n",
      "224: VD\n",
      "225: V\n",
      "226: V\n",
      "227: V\n",
      "228: V\n",
      "229: D\n",
      "230: VVVVVVD\n",
      "231: V\n",
      "232: VVVVVVVVVVVVVVVV\n",
      "233: V\n",
      "234: VD\n",
      "235: D\n",
      "236: D\n",
      "237: VVVD\n",
      "238: V\n",
      "239: V\n",
      "240: V\n",
      "241: V\n",
      "242: V\n",
      "243: VV\n",
      "244: V\n",
      "245: VD\n",
      "246: V\n",
      "247: VD\n",
      "248: VVD\n",
      "249: V\n",
      "total_reward =  -1050.0\n",
      "average episode reward =  -4.2\n"
     ]
    }
   ],
   "source": [
    "# @title Annotating data with intelligent dialog\n",
    "env = environment.AnnotatingDataset(annotator_real, the_detector, image_class_current)\n",
    "\n",
    "print('Running ', len(env.image_class), 'episodes with strategy IAD-Prob')\n",
    "\n",
    "%output_height 300\n",
    "print('intelligent dialog strategy')\n",
    "\n",
    "total_reward = 0\n",
    "# reset the gound truth because the user only needs to annotate the last 10% of data using the detector from the rest of the data\n",
    "new_ground_truth_all = []\n",
    "\n",
    "for i in range(len(env.image_class)):\n",
    "  print(i, end = ': ')\n",
    "  state = env.reset(current_index=i)\n",
    "\n",
    "  done = False\n",
    "  while not(done):\n",
    "    action = agent.get_next_action(state)\n",
    "    if action==0:\n",
    "      print('V', end='')\n",
    "    elif action==1:\n",
    "      print('D', end='')\n",
    "    next_state, reward, done, coordinates = env.step(action)\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "\n",
    "  dataset_id = env.current_image\n",
    "\n",
    "  # ground truth with which we will initialise the new user\n",
    "  new_ground_truth = {}\n",
    "  new_ground_truth['image_id'] = dataset_id\n",
    "  new_ground_truth['class_id'] = env.current_class\n",
    "  new_ground_truth['xmax'] = coordinates['xmax']\n",
    "  new_ground_truth['xmin'] = coordinates['xmin']\n",
    "  new_ground_truth['ymax'] = coordinates['ymax']\n",
    "  new_ground_truth['ymin'] = coordinates['ymin']\n",
    "  new_ground_truth_all.append(new_ground_truth)\n",
    "\n",
    "\n",
    "  if dataset_id not in all_annotations:\n",
    "    current_annotation = dict()\n",
    "    current_annotation['boxes'] = np.array([[coordinates['ymin'], coordinates['xmin'], coordinates['ymax'], coordinates['xmax']]], dtype=np.int32)\n",
    "    current_annotation['box_labels'] = np.array([env.current_class])\n",
    "    all_annotations[dataset_id] = current_annotation\n",
    "\n",
    "  else:\n",
    "    all_annotations[dataset_id]['boxes'] = np.append(all_annotations[dataset_id]['boxes'],  np.array([[coordinates['ymin'], coordinates['xmin'], coordinates['ymax'], coordinates['xmax']]], dtype=np.int32), axis=0)\n",
    "    all_annotations[dataset_id]['box_labels'] = np.append(all_annotations[dataset_id]['box_labels'], np.array([env.current_class]))     \n",
    "\n",
    "  print()\n",
    "\n",
    "print('total_reward = ', total_reward)    \n",
    "print('average episode reward = ', total_reward/len(env.image_class))\n",
    "\n",
    "new_ground_truth_all = pd.DataFrame(new_ground_truth_all)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "exp2_IAD_Prob_open_sourcing",
   "provenance": [
    {
     "file_id": "0Bz6XXZ1741KYUXRsNUI0c18wQVU",
     "timestamp": 1505896405546
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
